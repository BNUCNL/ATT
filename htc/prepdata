# emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode:nil -*-
# vi: set ft=python sts=4 ts=4 sw=4 et:

import os
import numpy as np
import nibabel as nib
import pandas as pd
import csv
import random

pjoin = os.path.join

def vox2MNI(vox,affine):
    vox_new = np.ones([4,1])
    vox_new[0:-1,0] = vox[:]
    MNI = affine.dot(vox_new)
    MNI_new = MNI[0:-1].tolist()    # transform array into list
    return sum(MNI_new,[])  # extend multiple list

def dice(image1,image2):
    image1_instead = image1
    image2_instead = image2
    image1_instead[image1_instead!=0]=1
    image2_instead[image2_instead!=0]=1
    overlap = image1*image2
    dice_num = 2*overlap.sum()/(image1.sum()+image2.sum())
    return dice_num

def random_split_list(raw_list):
    length_list = len(raw_list)
    split_list = random.sample(raw_list,length_list)
    pre_splitlist = split_list[0:length_list/2]
    post_splitlist = split_list[length_list/2:]
    return pre_splitlist,post_splitlist
    
def bluring():
    pass    

def apply_loadimg(dirs):
    return map(lambda x: nib.load(x).get_data(), dirs)


def probatlas(sesspar,sessid,contrast,filename,lbname,lbid,outputdir,probsplit):
    signals = [os.path.join(sesspar,sed,contrast,filename) for sed in sessid]
    ffsignals = apply_loadimg(signals)
    probdata = np.zeros([91,109,91,len(lbname)])
    header = nib.load(signals[0]).get_header()
    for areaid in lbid:   
        for sigid in range(len(signals)):
            probdata[:,:,:,areaid-1][ffsignals[sigid] == (areaid)] += 1
    probdata = probdata/len(sessid)
    for areaid in range(len(lbid)):
        img_new = nib.Nifti1Image(probdata[:,:,:,areaid],None,header)
        if probsplit == 'post':
            nib.save(img_new,outputdir + lbname[areaid] + '_post' + '.nii.gz')  
        elif probsplit == 'pre':
            nib.save(img_new,outputdir + lbname[areaid] + '_pre' + '.nii.gz')
        else:
            nib.save(img_new,outputdir + lbname[areaid] + '.nii.gz')  
    return probdata

def MPM(probdata,header,thr,outputdir,outname):
    areasnum = probdata.shape[3]
    probdata_new = np.zeros([91,109,91,areasnum+1])
    probdata[probdata<thr] = 0 
    probdata_new[:,:,:,1:areasnum+1] = probdata
    mpmdata = probdata_new.argmax(axis=3) 
    img_new = nib.Nifti1Image(mpmdata,None,header)
    nib.save(img_new,outputdir+outname+'.nii.gz')
    return mpmdata

# input variable,sessid
obj_file = open('/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/doc/dfsf/sub/subjID','rU')
sessid = obj_file.read().splitlines()
obj_file.close()
# input gender
pathsex = '/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/doc/dfsf/sub/'
gender = pd.read_csv(pathsex+'sex.csv')['gender'].tolist()
# output path
# outpath = '/nfs/j3/userhome/huangtaicheng/workingdir/try_htc/mt_analysis/'
outpath_par = '/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/BAA/results/yang_test/sub/sub_split/data/'
# lbname
areaname = ['rV3','lV3','rMT','lMT']
# lbid
areaid = [1,2,3,4]


#input variable,task
task = 'mt'
#input variable,contrast
contrast = 'motion'
idnum = len(sessid)
areanum = 4

volume = np.zeros([idnum,areanum])
mpsc = np.zeros([idnum,areanum])
mzstat = np.zeros([idnum,areanum])
ppsc = np.zeros([idnum,areanum])
pzstat = np.zeros([idnum,areanum])
peak_cor = np.zeros([idnum,areanum,3])
sessi = 0

# define pre and post index
pre_num = idnum/2
post_num = idnum - idnum/2
pre_gender = []
post_gender = []
pre_volume = np.zeros([pre_num,areanum])
post_volume = np.zeros([post_num,areanum])
pre_mpsc = np.zeros([pre_num,areanum])
post_mpsc = np.zeros([post_num,areanum])
pre_ppsc = np.zeros([pre_num,areanum])
post_ppsc = np.zeros([post_num,areanum])
pre_mzstat = np.zeros([pre_num,areanum])
post_mzstat = np.zeros([post_num,areanum])
pre_pzstat = np.zeros([pre_num,areanum])
post_pzstat = np.zeros([post_num,areanum])
pre_peak_cor = np.zeros([pre_num,areanum,3])
post_peak_cor = np.zeros([post_num,areanum,3])


for sess in sessid:
    # Q1:how to express names of mt_z5.0_ff.nii.gz
    pathmt = os.path.join(sesspar,sess,task,contrast,'mt_z5.0_ff.nii.gz')
    # Q2:how to express names of cope1.nii.gz
    pathbeta = os.path.join(sesspar,sess,task,contrast,'cope1.nii.gz')
    pathstat = os.path.join(sesspar,sess,task,contrast,'zstat1.nii.gz')
    img_zsta = nib.load(pathstat)
    data_zsta = img_zsta.get_data()
    img_mt = nib.load(pathmt)
    data_mt = img_mt.get_data()
    img_beta = nib.load(pathbeta)
    data_beta = img_beta.get_data()    
    
    affine = img_zsta.get_affine()
    header = img_zsta.get_header()
    
    for areai in range(areanum):
  
        temp = np.zeros([91,109,91]) 
        volume[sessi,areai] = np.sum(data_mt == (areai+1))*(2*2*2)      
        if data_beta[data_mt == (areai+1)] != []:
            # mean psc has multiplied 100
            mpsc[sessi,areai] = np.nanmean(data_beta[data_mt == (areai+1)])/100
            # peak psc has multiplied 100
            ppsc[sessi,areai] = np.nanmax(data_beta[data_mt == (areai+1)])/100  
            # mean zstate value
            mzstat[sessi,areai] = np.nanmean(data_zsta[data_mt == (areai+1)]) 
            # peak zstate value
            pzstat[sessi,areai] = np.nanmax(data_zsta[data_mt == (areai+1)])
        # peak coordinate,need a middle variable 'temp'        
        temp[data_mt == (areai+1)] = data_zsta[data_mt == (areai+1)]
        peak_cor[sessi,areai,:] = np.unravel_index(temp.argmax(),temp.shape)
        if not any(peak_cor[sessi,areai,:]):
            peak_cor[sessi,areai,:] = [np.nan,np.nan,np.nan]
        peak_cor[sessi,areai,:] = vox2MNI(peak_cor[sessi,areai,:],affine)
    sessi+=1
     
# pre-data & post-data
pre_enum,post_enum = random_split_list(range(len(list(sessid))))
pre_sessid = np.array(sessid)[pre_enum]
post_sessid = np.array(sessid)[post_enum]
for areai in range(areanum):
    pre_volume[:,areai] = volume[:,areai][pre_enum]
    post_volume[:,areai] = volume[:,areai][post_enum]
    pre_mpsc[:,areai] = mpsc[:,areai][pre_enum]
    post_mpsc[:,areai] = mpsc[:,areai][post_enum]
    pre_ppsc[:,areai] = ppsc[:,areai][pre_enum]
    post_ppsc[:,areai] = ppsc[:,areai][post_enum]
    pre_mzstat[:,areai] = mzstat[:,areai][pre_enum]
    post_mzstat[:,areai] = mzstat[:,areai][post_enum]
    pre_pzstat[:,areai] = pzstat[:,areai][pre_enum]
    post_pzstat[:,areai] = pzstat[:,areai][post_enum] 
    for cor in range(3):
        pre_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][pre_enum]
        post_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][post_enum]

for preindex in pre_enum:
    pre_gender.append(gender[preindex])  
for postindex in post_enum:
    post_gender.append(gender[postindex]) 
# make file
outpath = os.path.join(outpath_par,'rawcsv/')
for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'.csv'),'wb') as filecsv:
        writer_total = csv.writer(filecsv)
        writer_total.writerow(['NSPID',
                               'gender',
                               'volume',
                               'mean_psc',
                               'peak_psc',
                               'mean_zstate',
                               'peak_zstate',
                               'px','py','pz'])
        wholedata_total = zip(list(sessid),
                              gender,
                          list(volume[:,areai]),
                          list(mpsc[:,areai]),
                          list(ppsc[:,areai]),
                          list(mzstat[:,areai]),
                          list(pzstat[:,areai]),
                          list(peak_cor[:,areai,0]),
                          list(peak_cor[:,areai,1]),
                          list(peak_cor[:,areai,2]))
        writer_total.writerows(wholedata_total)
    filecsv.close()

# pre_enum
for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'_pre'+'.csv'),'wb') as filecsv:
        writer_pre = csv.writer(filecsv)
        writer_pre.writerow(['NSPID',
                            'gender',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
        wholedata_pre = zip(list(pre_sessid),
                            pre_gender,
                        list(pre_volume[:,areai]),
                        list(pre_mpsc[:,areai]),
                        list(pre_ppsc[:,areai]),
                        list(pre_mzstat[:,areai]),
                        list(pre_pzstat[:,areai]),
                        list(pre_peak_cor[:,areai,0]),
                        list(pre_peak_cor[:,areai,1]),
                        list(pre_peak_cor[:,areai,2]))
        writer_pre.writerows(wholedata_pre)
    filecsv.close()

# post_enum
for areai in range(areanum):
    with open(os.path.join(outpath,areaname[areai]+'_post'+'.csv'),'wb') as filecsv:
        writer_post = csv.writer(filecsv)
        writer_post.writerow(['NSPID',
                            'gender',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
        wholedata_post = zip(list(post_sessid),
                             post_gender,
                        list(post_volume[:,areai]),
                        list(post_mpsc[:,areai]),
                        list(post_ppsc[:,areai]),
                        list(post_mzstat[:,areai]),
                        list(post_pzstat[:,areai]),
                        list(post_peak_cor[:,areai,0]),
                        list(post_peak_cor[:,areai,1]),
                        list(post_peak_cor[:,areai,2]))
        writer_post.writerows(wholedata_post)
    filecsv.close()

# Now,work for probabilistic maps
thr_all = [0,0.1,0.2]

outpath_prob = os.path.join(outpath_par,'probabilistic/')

# prob
# All
probdata = probatlas(sesspar,sessid,'mt/motion','mt_z5.0_ff.nii.gz',areaname,areaid,outpath_prob,'all')
# Pre
probdata_pre = probatlas(sesspar,list(pre_sessid),'mt/motion','mt_z5.0_ff.nii.gz',areaname,areaid,outpath_prob,'pre')
# Post
probdata_post = probatlas(sesspar,list(post_sessid),'mt/motion','mt_z5.0_ff.nii.gz',areaname,areaid,outpath_prob,'post')

# MPM
for thr in thr_all:
    # All
    mpmdata = MPM(probdata,header,thr,outpath_prob,'MPM_p' +str(thr)+ '_all')
    # Pre
    mpmdata_pre = MPM(probdata_pre,header,thr,outpath_prob,'MPM_p'+str(thr)+'_pre')
    # Post
    mpmdata_post = MPM(probdata_post,header,thr,outpath_prob,'MPM_p'+str(thr)+'_post')


	
thr_all = [0,0.1,0.2]
for thr in thr_all:
    mpmdata = nib.load(os.path.join(outpath_par,'probabilistic','MPM_p'+str(thr)+'_all'+'.nii.gz')).get_data()

    sessi = 0
    for sess in sessid:
        # Q1:how to express names of mt_z5.0_ff.nii.gz
        # pathmt = os.path.join(sesspar,sess,task,contrast,'mt_z5.0_ff.nii.gz')
        # Q2:how to express names of cope1.nii.gz
        pathbeta = os.path.join(sesspar,sess,task,contrast,'cope1.nii.gz')
        pathstat = os.path.join(sesspar,sess,task,contrast,'zstat1.nii.gz')
        img_zsta = nib.load(pathstat)
        data_zsta = img_zsta.get_data()
        data_mt = mpmdata
        img_beta = nib.load(pathbeta)
        data_beta = img_beta.get_data()    
    
        for areai in range(areanum):
  
            temp = np.zeros([91,109,91]) 
            volume[sessi,areai] = np.sum(data_mt == (areai+1))*(2*2*2)      
            if data_beta[data_mt == (areai+1)] != []:
                # mean psc has multiplied 100
                mpsc[sessi,areai] = np.nanmean(data_beta[data_mt == (areai+1)])/100
                # peak psc has multiplied 100
                ppsc[sessi,areai] = np.nanmax(data_beta[data_mt == (areai+1)])/100  
                # mean zstate value
                mzstat[sessi,areai] = np.nanmean(data_zsta[data_mt == (areai+1)]) 
                # peak zstate value
                pzstat[sessi,areai] = np.nanmax(data_zsta[data_mt == (areai+1)])
            # peak coordinate,need a middle variable 'temp'        
            temp[data_mt == (areai+1)] = data_zsta[data_mt == (areai+1)]
            peak_cor[sessi,areai,:] = np.unravel_index(temp.argmax(),temp.shape)
            if not any(peak_cor[sessi,areai,:]):
                peak_cor[sessi,areai,:] = [np.nan,np.nan,np.nan]
            peak_cor[sessi,areai,:] = vox2MNI(peak_cor[sessi,areai,:],affine)
        sessi+=1
     
    # pre-data & post-data
    for areai in range(areanum):
        pre_volume[:,areai] = volume[:,areai][pre_enum]
        post_volume[:,areai] = volume[:,areai][post_enum]
        pre_mpsc[:,areai] = mpsc[:,areai][pre_enum]
        post_mpsc[:,areai] = mpsc[:,areai][post_enum]
        pre_ppsc[:,areai] = ppsc[:,areai][pre_enum]
        post_ppsc[:,areai] = ppsc[:,areai][post_enum]
        pre_mzstat[:,areai] = mzstat[:,areai][pre_enum]
        post_mzstat[:,areai] = mzstat[:,areai][post_enum]
        pre_pzstat[:,areai] = pzstat[:,areai][pre_enum]
        post_pzstat[:,areai] = pzstat[:,areai][post_enum] 
        for cor in range(3):
            pre_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][pre_enum]
            post_peak_cor[:,areai,cor] = peak_cor[:,areai,cor][post_enum]

    for preindex in pre_enum:
        pre_gender.append(gender[preindex])  
    for postindex in post_enum:
        post_gender.append(gender[postindex]) 
    # make file
    outpath = os.path.join(outpath_par,'rawcsv/')
    for areai in range(areanum):
        with open(os.path.join(outpath,areaname[areai]+'_groupthr'+str(thr)+'.csv'),'wb') as filecsv:
            writer_total = csv.writer(filecsv)
            writer_total.writerow(['NSPID',
                               'gender',
                               'volume',
                               'mean_psc',
                               'peak_psc',
                               'mean_zstate',
                               'peak_zstate',
                               'px','py','pz'])
            wholedata_total = zip(list(sessid),
                              gender,
                          list(volume[:,areai]),
                          list(mpsc[:,areai]),
                          list(ppsc[:,areai]),
                          list(mzstat[:,areai]),
                          list(pzstat[:,areai]),
                          list(peak_cor[:,areai,0]),
                          list(peak_cor[:,areai,1]),
                          list(peak_cor[:,areai,2]))
            writer_total.writerows(wholedata_total)
        filecsv.close()

# pre_enum
    for areai in range(areanum):
        with open(os.path.join(outpath,areaname[areai]+'_groupthr'+str(thr)+'_pre'+'.csv'),'wb') as filecsv:
            writer_pre = csv.writer(filecsv)
            writer_pre.writerow(['NSPID',
                            'gender',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
            wholedata_pre = zip(list(pre_sessid),
                            pre_gender,
                        list(pre_volume[:,areai]),
                        list(pre_mpsc[:,areai]),
                        list(pre_ppsc[:,areai]),
                        list(pre_mzstat[:,areai]),
                        list(pre_pzstat[:,areai]),
                        list(pre_peak_cor[:,areai,0]),
                        list(pre_peak_cor[:,areai,1]),
                        list(pre_peak_cor[:,areai,2]))
            writer_pre.writerows(wholedata_pre)
        filecsv.close()

# post_enum
    for areai in range(areanum):
        with open(os.path.join(outpath,areaname[areai]+'_groupthr'+str(thr)+'_post'+'.csv'),'wb') as filecsv:
            writer_post = csv.writer(filecsv)
            writer_post.writerow(['NSPID',
                            'gender',
                            'volume',
                            'mean_psc',
                            'peak_psc',
                            'mean_zstate',
                            'peak_zstate',
                            'px','py','pz'])
            wholedata_post = zip(list(post_sessid),
                             post_gender,
                        list(post_volume[:,areai]),
                        list(post_mpsc[:,areai]),
                        list(post_ppsc[:,areai]),
                        list(post_mzstat[:,areai]),
                        list(post_pzstat[:,areai]),
                        list(post_peak_cor[:,areai,0]),
                        list(post_peak_cor[:,areai,1]),
                        list(post_peak_cor[:,areai,2]))
            writer_post.writerows(wholedata_post)
        filecsv.close()


