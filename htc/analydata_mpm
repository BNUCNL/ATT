# emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode:nil -*-
# vi: set ft=python sts=4 ts=4 sw=4 et:

import nibabel as nib
import numpy as np
import os
import pandas as pd
import matplotlib.pyplot as plt
import copy

pjoin = os.path.join

def vox2MNI(vox,affine):
    vox_new = np.ones([4,1])
    vox_new[0:-1,0] = vox[:]
    MNI = affine.dot(vox_new)
    MNI_new = MNI[0:-1].tolist()
    return sum(MNI_new,[])

def apply_loadimg(dirs):
    return map(lambda x: nib.load(x).get_data(),dirs)

def calcorr_prob(predata,postdata,alldata,lbid):
# Calculate correlation between pre-,post- and all- data
    lbid_new = map(lambda id:id-1,lbid)
    coef_prepost = np.zeros([len(lbid),1])
    coef_preall = np.zeros([len(lbid),1])
    coef_postall = np.zeros([len(lbid),1])
    for id in lbid_new:
        coef_prepost[id] = np.corrcoef(predata[id].reshape(91*109*91,),postdata[id].reshape(91*109*91,))[0][1]
        coef_preall[id] = np.corrcoef(predata[id].reshape(91*109*91,),alldata[id].reshape(91*109*91,))[0][1]
        coef_postall[id] = np.corrcoef(postdata[id].reshape(91*109*91,),alldata[id].reshape(91*109*91,))[0][1]
    return coef_prepost,coef_preall,coef_postall

def dice(image1_ori,image2_ori):
    image1 = copy.deepcopy(image1_ori)
    image2 = copy.deepcopy(image2_ori)
    image1[image1!=0] = 1
    image2[image2!=0] = 1
    overlap = image1*image2
    dicevalue = 2*overlap.sum()/(image1.sum()+image2.sum())
    return dicevalue

def caldice_prob(predata,postdata,alldata,lbid):
# Calculate dice between pre-,post- and all- data
    lbid_new = map(lambda id:id-1,lbid)
    dice_prepost = np.zeros(len(lbid))
    dice_preall = np.zeros(len(lbid))
    dice_postall = np.zeros(len(lbid))
    for id in lbid_new:
        dice_prepost[id] = dice(predata[id],postdata[id])
        dice_preall[id] = dice(predata[id],alldata[id])
        dice_postall[id] = dice(postdata[id],alldata[id])
    return dice_prepost,dice_preall,dice_postall

def peakprob(predata,postdata,alldata,affine,lbid):
# 4*4 matrix.3*4 -> peak coordinate;1*4 -> peak probability
    lbid_new = map(lambda id:id-1,lbid)
    peakcor = lambda data:np.unravel_index(data.argmax(),[91,109,91])
    peakval = lambda data:np.max(data)
    mni_all = np.zeros([4,3])
    mni_pre = np.zeros([4,3])
    mni_post = np.zeros([4,3])
    vox_all = map(peakcor,alldata)
    vox_pre = map(peakcor,predata)
    vox_post = map(peakcor,postdata)    
# calculate mni coordinates
    for id in lbid_new:
        mni_all[id,:] = vox2MNI(vox_all[id],affine) 
        mni_pre[id,:] = vox2MNI(vox_pre[id],affine)
        mni_post[id,:] = vox2MNI(vox_post[id],affine)
# calculate peak values
    peakpro_all = map(peakval,alldata)
    peakpro_pre = map(peakval,predata)
    peakpro_post = map(peakval,postdata)
# combine coordinates and values 
    prob_all = zip(mni_all,peakpro_all)
    prob_pre = zip(mni_pre,peakpro_pre)
    prob_post = zip(mni_post,peakpro_post)    
    return prob_all,prob_pre,prob_post

def loadcsv(csvpath,lbname,dataclass):
    if dataclass == 'pre':
        csvsignals = [csvpath + lb + '_pre.csv' for lb in lbname]
    elif dataclass == 'post':
        csvsignals = [csvpath + lb + '_post.csv' for lb in lbname]
    else:
        csvsignals = [csvpath + lb + '.csv' for lb in lbname]
    csvdata = [pd.read_csv(cc) for cc in csvsignals]
    return csvdata

def countmissdata(csvdata,lbid):
# Some areas in subjects may not exist
# Therefore it's meaningful to count numbers of it
# The format of data is [whole numbers,male numbers,female numbers],
# each row means areas arrayed by lbname(lbid)
    misseddata = np.zeros([len(lbid),3])
    for i in range(len(lbid)):
        misseddata[i][0] = sum(csvdata[i]['volume'] == 0)
        misseddata[i][1] = sum(csvdata[i]['volume'][csvdata[0]['gender']== 'm']==0)
        misseddata[i][2] = sum(csvdata[i]['volume'][csvdata[0]['gender']== 'f']==0)
    return misseddata

def deletenas(csvdata):
# csvdata is a four(area numbers) index list,each index contains DataFrame of an area
    delcsvdata = []
    for i in range(len(csvdata)):
        temp = csvdata[i].dropna(axis=0,how = 'any')
        delcsvdata.append(temp)
    return delcsvdata

def descridata(csvdata):
    descsvdata = []
    for i in range(len(csvdata)):
        temp = csvdata[i].describe()
        descsvdata.append(temp)
    return descsvdata

def plotbars(desdata_all,desdata_m,desdata_f,width,lbnames,prop,dataclass):
    N = len(lbnames)
    allmeans = []
    allstds = []
    menmeans = []
    menstds = []
    womenmeans = []
    womenstds = []
    for i in range(N):
        allmeans.append(desdata_all[i][prop]['mean'])
        allstds.append(desdata_all[i][prop]['std'])
        menmeans.append(desdata_m[i][prop]['mean'])
        menstds.append(desdata_m[i][prop]['std'])
        womenmeans.append(desdata_f[i][prop]['mean'])
        womenstds.append(desdata_f[i][prop]['std'])
    ind = np.arange(N)
    fig,ax = plt.subplots()
    rects1 = ax.bar(ind, allmeans, width, color='r', yerr=allstds)    
    rects2 = ax.bar(ind+width, menmeans, width, color = 'y', yerr=menstds)
    rects3 = ax.bar(ind+2*width, womenmeans, width, color = 'b', yerr=womenstds)
# add some text for labels,title and axes ticks
    ax.set_ylabel(prop)
    if dataclass == 'all':
        ax.set_title('Values by areas and gender (All)')
    elif dataclass == 'pre':
        ax.set_title('Values by areas and gender (Pre)')
    else:
        ax.set_title('Values by areas and gender (Post)')    
    ax.set_xticks(ind + width)
    ax.set_xticklabels(lbnames) 
    ax.legend((rects1[0],rects2[0],rects3[0]),('All','Men','Women'))   
    plt.show()

def savecsv(csvdel,lbname,dataclass,outpath): 
    for i in range(len(lbname)):
        if dataclass == 'pre':
            csvdel[i].to_csv(outpath+lbname[i]+'_pre.csv',index = False)
        elif dataclass == 'post':
            csvdel[i].to_csv(outpath+lbname[i]+'_post.csv',index = False)
        else:
            csvdel[i].to_csv(outpath+lbname[i]+'.csv',index = False)

def intersection(a, b):
    c = [val for val in a if val in b]
    return c   

def combinecsv(csvname, csvpath, outputdir):
# csvname,in my programs are also areanames
# If you want to combine lMT.csv - rMT.csv ,just input 'MT' in csvname.
# Also it will calculate two splited data,with suffix of _pre and _post
# If you want to combine mpmmask data , in my programs you just need to input 
# 'MT_groupthr'+str(thr) as csvname

    lcsvfile = []
    rcsvfile = []
    lcsvdata = []
    rcsvdata = []
    lcsvdata_combine = []
    rcsvdata_combine = []
    combined_sess = []
    # make csv file list
    lcsvfile.append('l'+csvname+'.csv')
    lcsvfile.append('l'+csvname+'_pre'+'.csv')
    lcsvfile.append('l'+csvname+'_post'+'.csv')
    
    rcsvfile.append('r'+csvname+'.csv')
    rcsvfile.append('r'+csvname+'_pre'+'.csv')
    rcsvfile.append('r'+csvname+'_post'+'.csv')    
    # load data from this list
    for filename in lcsvfile:
        lcsvdata.append(pd.read_csv(pjoin(csvpath,filename)))
    for filename in rcsvfile:
        rcsvdata.append(pd.read_csv(pjoin(csvpath,filename))) 
    # Combined sessid
    for i in range(len(lcsvfile)):
        combined_sess.append(intersection(lcsvdata[i]['NSPID'].tolist(),rcsvdata[i]['NSPID'].tolist()))
    # Get combined data
    for i in range(len(combined_sess)):
        lcsvdata_combine.append(lcsvdata[i][lcsvdata[i]['NSPID'].isin(combined_sess[i])])
        rcsvdata_combine.append(rcsvdata[i][rcsvdata[i]['NSPID'].isin(combined_sess[i])])
    # make .csv file
    for i in range(len(combined_sess)):
        lcsvdata_combine[i].to_csv(pjoin(outputdir,lcsvfile[i]),index=False)
        rcsvdata_combine[i].to_csv(pjoin(outputdir,rcsvfile[i]),index=False)
    return lcsvdata_combine,rcsvdata_combine


pathdata = '/nfs/j3/userhome/huangtaicheng/workingdir/parcellation_MT/BAA/results/yang_test/sub/sub_split'
# Read data from csvdata and probdata
csvdata = pjoin(pathdata,'data','rawcsv/')
probdata = pjoin(pathdata,'data','probabilistic/')
# Here we will generate data(.csv) in path of csvdata_nonan
csvdata_nonan = pjoin(pathdata,'data','delcsv/')

lbid = [1,2,3,4]
lbname = ['rV3','lV3','rMT','lMT']
prop = ['volume','mean_psc','peak_psc','mean_zstate','peak_zstate','px','py','pz']

# thr = 0
# thr = 0.1
thr = 0.2

grouplbname = ['rV3_groupthr'+str(thr),'lV3_groupthr'+str(thr),'rMT_groupthr'+str(thr),'lMT_groupthr'+str(thr)]

affine = nib.load(probdata + '/' + 'lMT.nii.gz').get_affine()
malenumber = sum(pd.read_csv(csvdata + 'lMT.csv')['gender'] == 'm')
femalenumber = sum(pd.read_csv(csvdata + 'lMT.csv')['gender'] == 'f')

problist_all = [probdata + '/' + name + '.nii.gz' for name in lbname]
problist_pre = [probdata + '/' + name + '_pre.nii.gz' for name in lbname]
problist_post = [probdata + '/' + name + '_post.nii.gz' for name in lbname]

mpmlist_all = [probdata + '/' + 'MPM_p' + str(thr) + '_all.nii.gz']
mpmlist_pre = [probdata + '/' + 'MPM_p' + str(thr) + '_pre.nii.gz']
mpmlist_post = [probdata + '/' + 'MPM_p' + str(thr) + '_post.nii.gz']

probsignal_all = apply_loadimg(problist_all)
probsignal_pre = apply_loadimg(problist_pre)
probsignal_post = apply_loadimg(problist_post)

mpmsignal_all = apply_loadimg(mpmlist_all)[0]
mpmsignal_pre = apply_loadimg(mpmlist_pre)[0]
mpmsignal_post = apply_loadimg(mpmlist_post)[0]

# Calculate correlation between pre- post- and all- data in probabilistic map
corprepost_prob, corpreall_prob, corpostall_prob = calcorr_prob(probsignal_pre,probsignal_post,probsignal_all,lbid)
# Calculate correlation between pre- post- and all- data in MPM
calcorr_mpm = lambda x,y:np.corrcoef(x.reshape(91*109*91,),y.reshape(91*109*91,))[0][1]
corprepost_mpm = calcorr_mpm(mpmsignal_pre,mpmsignal_post)
corpreall_mpm = calcorr_mpm(mpmsignal_all,mpmsignal_pre)
corpostall_mpm = calcorr_mpm(mpmsignal_all,mpmsignal_post)
# Calculate dice values between pre- post- and all- data in probabilistic map
diceprepost_prob, dicepreall_prob, dicepostall_prob = caldice_prob(probsignal_pre,probsignal_post,probsignal_all,lbid)
# Calculate dice values between pre- post- and all- data in MPM
diceprepost_mpm = dice(mpmsignal_pre,mpmsignal_post)
dicepreall_mpm = dice(mpmsignal_all,mpmsignal_pre)
dicepostall_mpm = dice(mpmsignal_all,mpmsignal_post)


# Now,for peak probility and coordinates
probpeak_all,probpeak_pre,probpeak_post = peakprob(probsignal_pre,probsignal_post,probsignal_all,affine,lbid)

# Load information from .csv
csv_all = loadcsv(csvdata,grouplbname,'all')
csv_pre = loadcsv(csvdata,grouplbname,'pre')
csv_post = loadcsv(csvdata,grouplbname,'post')
# count numbers of missed roi
miss_all = countmissdata(csv_all,lbid)
miss_pre = countmissdata(csv_pre,lbid)
miss_post = countmissdata(csv_post,lbid)
# Delete rows in NA
csvdel_all = deletenas(csv_all)
csvdel_pre = deletenas(csv_pre)
csvdel_post = deletenas(csv_post) 
# save csv
savecsv(csvdel_all,grouplbname,'all',csvdata_nonan)
savecsv(csvdel_pre,grouplbname,'pre',csvdata_nonan)
savecsv(csvdel_post,grouplbname,'post',csvdata_nonan)

# Describe data
csvdes_all = descridata(csvdel_all)
csvdes_pre = descridata(csvdel_pre)
csvdes_post = descridata(csvdel_post)

csvdel_m_all = []
csvdel_f_all = []
csvdel_m_pre = []
csvdel_f_pre = []
csvdel_m_post = []
csvdel_f_post = []
for i in range(len(csvdes_all)):
    csvdel_m_all.append(csvdel_all[i][csvdel_all[i]['gender'] == 'm'])
    csvdel_f_all.append(csvdel_all[i][csvdel_all[i]['gender'] == 'f'])
    csvdel_m_pre.append(csvdel_pre[i][csvdel_pre[i]['gender'] == 'm'])
    csvdel_f_pre.append(csvdel_pre[i][csvdel_pre[i]['gender'] == 'f'])
    csvdel_m_post.append(csvdel_post[i][csvdel_post[i]['gender'] == 'm'])
    csvdel_f_post.append(csvdel_post[i][csvdel_post[i]['gender'] == 'f'])
csvdes_m_all = descridata(csvdel_m_all)
csvdes_f_all = descridata(csvdel_f_all)
csvdes_m_pre = descridata(csvdel_m_pre)
csvdes_f_pre = descridata(csvdel_f_pre)
csvdes_m_post = descridata(csvdel_m_post)
csvdes_f_post = descridata(csvdel_f_post)

#Combined data together
combinecsv('MT_groupthr'+str(thr),csvdata_nonan,pjoin(csvdata_nonan,'combinedcsv/'))
combinecsv('V3_groupthr'+str(thr),csvdata_nonan,pjoin(csvdata_nonan,'combinedcsv/'))

# plot bars 
for propname in prop:    
    plotbars(csvdes_all,csvdes_m_all,csvdes_f_all,0.2,grouplbname,propname,'all')
    plotbars(csvdes_pre,csvdes_m_pre,csvdes_f_pre,0.2,grouplbname,propname,'pre')
    plotbars(csvdes_post,csvdes_m_post,csvdes_f_post,0.2,grouplbname,propname,'post')


